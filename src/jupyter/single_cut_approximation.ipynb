{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal is to approximate a 2d interpolation funciton by using 1d interpolation funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from collections import namedtuple\n",
    "from typing import List\n",
    "\n",
    "from scipy.special import comb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from algorithms import create_interp_1d_funcs, create_interp_2d_funcs, sigma_f1d, sigma_f2d\n",
    "from data_utils import create_1d_data, create_2d_data\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test approximate vs. 2d interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def f(x):\n",
    "            return np.array([datum[0]*np.sin(datum[1]) + datum[1] + datum[2] for datum in x]).reshape(-1, 1)\n",
    "\n",
    "        # ----creating training data----\n",
    "        primary_cut_center = [0, 0, 0]\n",
    "        x_1d = create_1d_data(x_range=(-8, 8, 1), cut_center=primary_cut_center)\n",
    "        x_2d = create_2d_data(x1_range=(-8, 8, 1), x2_range=(-8, 8, 1), cut_center=primary_cut_center)\n",
    "        y_1d = f(x_1d)\n",
    "        y_2d = f(x_2d)\n",
    "\n",
    "        # ----creating the interpolation functions----\n",
    "        f0 = f(np.array([primary_cut_center]))\n",
    "        f_1d = create_interp_1d_funcs(x_1d, y_1d, primary_cut_center)\n",
    "        f_2d = create_interp_2d_funcs(x_2d, y_2d, primary_cut_center)\n",
    "\n",
    "        # ----Testing----\n",
    "        test_datum = [1.45, 2.2823, 0.2782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_part of sigma_2d for f01: [[-2.2823]]\n"
     ]
    }
   ],
   "source": [
    "# ---- the negative part of sigma2d for f01-----\n",
    "neg_part = -(f_1d[0](test_datum[0]) - f0) - (f_1d[1](test_datum[1]) - f0) - f0\n",
    "print(f'net_part of sigma_2d for f01: {neg_part}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f01_interpolated: [3.37773063]\n"
     ]
    }
   ],
   "source": [
    "# ----testing the first 2d interpolated funciton --> f01----\n",
    "\n",
    "f01_interpolated = f_2d[0][0](test_datum[0], test_datum[1])\n",
    "print(f'f01_interpolated: {f01_interpolated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f01_approximated: [[3.42484694]]\n"
     ]
    }
   ],
   "source": [
    "# ----approximating f01----\n",
    "secondary_cut_center = [1, 1 ,primary_cut_center[2]] # or different cutcenter altoghether? TESTED: Z has to be the same as primary cut_center\n",
    "secondary_x_1d = create_1d_data(x_range=(-8, 8, 1), cut_center=secondary_cut_center)\n",
    "secondary_y_1d = f(secondary_x_1d)\n",
    "secondary_f_1d = create_interp_1d_funcs(secondary_x_1d, secondary_y_1d, secondary_cut_center)\n",
    "secondary_f0 = f(np.array([secondary_cut_center]))\n",
    "\n",
    "f01_approximated = secondary_f0 + (secondary_f_1d[0](test_datum[0]) - secondary_f0) + (secondary_f_1d[1](test_datum[1]) - secondary_f0) \n",
    "print(f'f01_approximated: {f01_approximated}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprizingly changing the **x and y** coordinate of the **secondary_cut_center** does **NOT** change the **f01_approximated**. This is the same as saying:\n",
    "\n",
    "$$F_{01}(x, y, \\hat{z}) = F(\\hat{x}, \\hat{y}, \\hat{z}) + [F(x, \\hat{y}, \\hat{z}) - F(\\hat{x}, \\hat{y}, \\hat{z})] +  [F(\\hat{x}, y, \\hat{z}) - F(\\hat{x}, \\hat{y}, \\hat{z})]$$ \n",
    "is the same as:\n",
    "$$F_{01}(x, y, \\hat{z}) = F(\\bar{x}, \\bar{y}, \\hat{z}) + [F(x, \\bar{y}, \\hat{z}) - F(\\bar{x}, \\bar{y}, \\hat{z})] +  [F(\\bar{x}, y, \\hat{z}) - F(\\bar{x}, \\bar{y}, \\hat{z})]$$\n",
    "\n",
    "where primary cut center: $$(\\hat{x}, \\hat{y}, \\hat{z})$$ \n",
    "and secondary cut center: $$(\\bar{x}, \\bar{y}, \\hat{z})$$\n",
    "\n",
    "**Turns out this is only the case if the x, and y variables are decouples (are linear) in the F function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation\n",
    "Now we try to automate the approximation part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important task seems to be the orgonization of the data that is used to create the 1D interpolation functions.\n",
    "I am going to think of this task as follows:\n",
    "1. There are two cut centers CC1 and CC2\n",
    "2. Each CC has n dimentions\n",
    "3. We need data that lies on each of the axis of the two cut centers (imagine each cut center as origin point of a coordinate system)\n",
    "4. Hence we need 2*n set of points\n",
    "5. Then for the original 1D interpolation functions such as (e.g. n=3, CC1=$(\\hat{x},\\hat{y},\\hat{z})$ ) $f(x,\\hat{y},\\hat{z})$ we need a set of three dimensional points with their first dimension vary around $\\hat{x}$, the second dimension is set to $\\hat{y}$ and their third dimension is set to $\\hat{z}$\n",
    "6. And hence for an approximation 1D interpolation such as (e.g. n=3, CC1=$(\\hat{x},\\hat{y},\\hat{z})$ and CC2=$(\\bar{x},\\bar{y},\\bar{z})$ ) $f(x,\\bar{y},\\hat{z})$ we need a set of three dimensional data points with their first dimension vary around $\\bar{x}$, the second dimension fixed at $\\bar{y}$ and their third dimension set to $\\hat{z}$\n",
    "    - I was just now wondering if in this case the first dimention should vary around $\\hat{x}$ or $\\bar{x}$, I believe that should not matter, in fact there might be a overlap if the range is large enough and $\\hat{x}$ and $\\bar{x}$ are close to each other. Perhaps using the one that is closer to the test data ( but we should not be thinking about test points at the training time (otherwise we will overfit) so discard this thought).\n",
    "    \n",
    "**Note:**\n",
    "We have so far thought of the points without their label or value (we have only been talking about how to construct (x,y,z) by mix and matching different dimentions, but how about F(x,y,z)? \n",
    "So in practice we would need $k*(n + 2*\\binom{n}{2})$  (x,y,z) and F(x,y,z) for training (k is the number of data points in each of n dimensions per CC) and each 1D interpolation function only uses one set of k points. \n",
    "\n",
    "So how should we do this? \n",
    "- should we create all data-value pairs before hand (which is similar to real world)\n",
    "- or should we take in the (x,y,z) points and calculate their values on demand by passing the F (which is more simulation, but easier)\n",
    "\n",
    "It seems more robust to create the training data beforehand (this way we can also compare it with other standard ML algorithms). So then the question becomes how do we orgonize them in a way that we would be able to access them for training each of the 1D interpolation functions? basically we need $n + 2*\\binom{n}{2}$ bins of coordinate-value pairs which can be accessed by an n (or so) variable keys e.g: I need all point-values for a 1D interpolation function that is related to $(\\bar{x}free,\\bar{y}fixed,\\hat{z}fixed)$\n",
    "\n",
    "How can I orgonize this? Use a dictionary with key being a string made from i, j, CC1, CC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0,0,0]_0_[1,1,1]_2'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KeyInfo = namedtuple('KeyInfo', ['primary_cut_center', 'varying_index', 'secondary_cut_center', 'fixed_index'], defaults=(None,)*2)\n",
    "\n",
    "def create_key(key_info: KeyInfo) -> str:\n",
    "    key = f'{key_info.primary_cut_center}_{key_info.varying_index}_{key_info.secondary_cut_center}_{key_info.fixed_index}'.replace(' ', '')\n",
    "    return key\n",
    "\n",
    "key_info = KeyInfo([0,0,0], 0, [1,1,1], 2)\n",
    "create_key(key_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data for each interpolation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetInfo = namedtuple('DatasetInfo', ['data_range', 'primary_cut_center' ,'varying_index', 'secondary_cut_center', 'fixed_index'], defaults=(None,)*2)\n",
    "\n",
    "\n",
    "def create_interpolation_data(dataset_info: DatasetInfo) -> np.ndarray:\n",
    "    assert dataset_info.varying_index != dataset_info.fixed_index, 'varying index cannot be the same as the fixed index'\n",
    "    single_axis_data = np.arange(*dataset_info.data_range)\n",
    "    dataset = np.repeat([dataset_info.primary_cut_center], len(single_axis_data), axis=0)\n",
    "    if dataset_info.secondary_cut_center:\n",
    "        dataset[:, dataset_info.fixed_index] = dataset_info.secondary_cut_center[dataset_info.fixed_index]\n",
    "        dataset[:, dataset_info.varying_index] = single_axis_data + dataset_info.secondary_cut_center[dataset_info.varying_index]\n",
    "    else:\n",
    "        dataset[:, dataset_info.varying_index] = single_axis_data + dataset_info.primary_cut_center[dataset_info.varying_index]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.9,  1.2,  2.3],\n",
       "       [-1.9,  1.2,  2.3],\n",
       "       [-0.9,  1.2,  2.3],\n",
       "       [ 0.1,  1.2,  2.3],\n",
       "       [ 1.1,  1.2,  2.3],\n",
       "       [ 2.1,  1.2,  2.3],\n",
       "       [ 3.1,  1.2,  2.3],\n",
       "       [ 4.1,  1.2,  2.3],\n",
       "       [ 5.1,  1.2,  2.3],\n",
       "       [ 6.1,  1.2,  2.3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsetinfo = DatasetInfo(data_range=[-5,5,1],\n",
    "                       primary_cut_center=[1.1, 1.2, 1.3],\n",
    "                       varying_index=0,\n",
    "                       secondary_cut_center=[2.1, 2.2, 2.3],\n",
    "                       fixed_index=2\n",
    "                      )\n",
    "\n",
    "make_interpolation_data(dsetinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training_data_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.array([datum[0]*np.sin(datum[1]) + datum[1] + datum[2] for datum in x]).reshape(-1, 1)\n",
    "\n",
    "TrainingSet = namedtuple('TrainingSet', ['X','Y'])\n",
    "\n",
    "def create_data_dict(data_range, f, primary_cut_center, secondary_cut_center):\n",
    "    data_dict = {}\n",
    "    n = len(primary_cut_center)\n",
    "    for i in range(n):\n",
    "        dataset_info = DatasetInfo(data_range, primary_cut_center, i)\n",
    "        key_info = KeyInfo(primary_cut_center, i)\n",
    "        \n",
    "        X = create_interpolation_data(dataset_info)\n",
    "        Y = f(X).reshape(-1,1)\n",
    "        training_set = TrainingSet(X,Y)\n",
    "        key = create_key(key_info)\n",
    "        data_dict[key] = training_set\n",
    "        \n",
    "    for i in range(0, n-1, 1):\n",
    "        for j in range(i+1, n, 1):\n",
    "            for k in range(2):\n",
    "                if k==0:\n",
    "                    dataset_info = DatasetInfo(data_range, primary_cut_center, i, secondary_cut_center, j)\n",
    "                    key_info = KeyInfo(primary_cut_center, i, secondary_cut_center, j)\n",
    "                else:\n",
    "                    dataset_info = DatasetInfo(data_range, primary_cut_center, j, secondary_cut_center, i)\n",
    "                    key_info = KeyInfo(primary_cut_center, j, secondary_cut_center, i)\n",
    "                X = create_interpolation_data(dataset_info)\n",
    "                Y = f(X).reshape(-1,1)\n",
    "                training_set = TrainingSet(X,Y)\n",
    "                key = create_key(key_info)\n",
    "                data_dict[key] = training_set\n",
    "                \n",
    "    return data_dict\n",
    "    \n",
    "data_dict = create_data_dict([-2,2,1], f, [0,0,0], [1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
